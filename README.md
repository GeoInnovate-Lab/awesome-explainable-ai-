# Recent Publications in Explainable AI and their summaries
A repository for summaries of recent explainable AI/Interpretable ML approaches


| Title                                                                                                                                                                                                                    |            Venue          |         Year         |        Code        |                  Keywords                  |              Summary              |
| :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  | :------------------------ | :------------------- | :----------------- | :----------------------------------------- | :-------------------------------- |
| [Towards A Rigorous Science of Interpretable Machine Learning](https://arxiv.org/abs/1702.08608) | arXiv | 2017 | N/A | `Review Paper` | [Link]() |
| [Transparency: Motivations and Challenges](https://arxiv.org/abs/1708.01870) | arXiv | 2017 | N/A | `Review Paper` | [Link]() |
| [The Mythos of Model Interpretability](https://dl.acm.org/doi/10.1145/3236386.3241340) | arXiv | 2018 | N/A | `Review Paper` | [Link]() |
| [Human Factors in Model Interpretability: Industry Practices, Challenges, and Needs](https://dl.acm.org/doi/10.1145/3392878) | arXiv | 2020 | N/A | `Review Paper` | [Link]() |
| [Interpreting Interpretability: Understanding Data Scientists’ Use of Interpretability Tools for Machine Learning](http://www-personal.umich.edu/~harmank/Papers/CHI2020_Interpretability.pdf) | CHI | 2020 | N/A | `Review Paper` | [Link]() |
| [Human Evaluation of Models Built for Interpretability](https://ojs.aaai.org/index.php/HCOMP/article/view/5280/5132) | AAAI | 2019 | N/A | `Human in the loop` | [Link]() |
| [Manipulating and Measuring Model Interpretability](https://arxiv.org/abs/1802.07810) | CHI | 2021 | N/A | `` | [Link]() |
| [Interpretable classifiers using rules and Bayesian analysis: Building a better stroke prediction model](https://arxiv.org/abs/1511.01644) | arXiv | 2015 | N/A | `` | [Link]() |
| [Interpretable Decision Sets: A Joint Framework for Description and Prediction](https://www-cs-faculty.stanford.edu/people/jure/pubs/interpretable-kdd16.pdf) | KDD | 2016 | N/A | `` | [Link]() |
| [Intelligible Models for HealthCare: Predicting Pneumonia Risk and Hospital 30-day Readmission](https://people.dbmi.columbia.edu/noemie/papers/15kdd.pdf) | KDD | 2015 | N/A | `` | [Link]() |
| [Deep Learning for Case-Based Reasoning through Prototypes: A Neural Network that Explains Its Predictions](https://arxiv.org/abs/1710.04806) | AAAI | 2018 | N/A | `` | [Link]() |
| [Learning Optimized Risk Scores](https://arxiv.org/pdf/1610.00168.pdf) | JMLR | 2019 | N/A | `` | [Link]() |
| ["Why Should I Trust You?": Explaining the Predictions of Any Classifier](https://arxiv.org/abs/1602.04938) | KDD | 2016 | N/A | `` | [Link]() |
| [A Unified Approach to Interpreting Model Predictions](https://proceedings.neurips.cc/paper_files/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf) | NeurIPS | 2017 | N/A | `` | [Link]() |
| [SmoothGrad: removing noise by adding noise](https://arxiv.org/abs/1706.03825) | ICML (Workshop) | 2017 | [Github](https://github.com/pair-code/saliency) | `` | [Link]() |
| [NoiseGrad — Enhancing Explanations by Introducing Stochasticity to Model Weights](https://cdn.aaai.org/ojs/20561/20561-13-24574-1-2-20220628.pdf) | AAAI | 2022 | [Github](https://github.com/understandable-machine-intelligence-lab/NoiseGrad) | `` | [Link]() |
